{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SL8-Hyperparameter Tuning",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO9y9tnhpIn_"
      },
      "source": [
        "#**Hyper-Parameter Tuning**\r\n",
        "\r\n",
        "Machine learning algorithms have hyperparameters that allow you to tailor the behavior of the algorithm to your specific dataset.\r\n",
        "\r\n",
        "Hyperparameters are different from parameters, which are the internal coefficients or weights for a model found by the learning algorithm. Unlike parameters, hyperparameters are specified by the practitioner when configuring the model.\r\n",
        "\r\n",
        "Typically, it is challenging to know what values to use for the hyperparameters of a given algorithm on a given dataset, therefore it is common to use random or grid search strategies for different hyperparameter values.\r\n",
        "\r\n",
        "The more hyperparameters of an algorithm that you need to tune, the slower the tuning process. Therefore, it is desirable to select a minimum subset of model hyperparameters to search or tune.\r\n",
        "\r\n",
        "Not all model hyperparameters are equally important. Some hyperparameters have an outsized effect on the behavior, and in turn, the performance of a machine learning algorithm.\r\n",
        "\r\n",
        "As a machine learning practitioner, you must know which hyperparameters to focus on to get a good result quickly.\r\n",
        "\r\n",
        "![hpt.png](data:image/png;base64,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)\r\n",
        "\r\n",
        "###***Hyper-Parameters for Logistic Regression***\r\n",
        "\r\n",
        "Logistic regression does not really have any critical hyperparameters to tune.\r\n",
        "\r\n",
        "Sometimes, you can see useful differences in performance or convergence with different solvers (solver).\r\n",
        "\r\n",
        "* solver in [‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’]\r\n",
        "Regularization (penalty) can sometimes be helpful.\r\n",
        "\r\n",
        "* penalty in [‘none’, ‘l1’, ‘l2’, ‘elasticnet’]\r\n",
        "Note: not all solvers support all regularization terms.\r\n",
        "\r\n",
        "* The C parameter controls the penality strength, which can also be effective.\r\n",
        "C in [100, 10, 1.0, 0.1, 0.01]\r\n",
        "\r\n",
        "###***Hyper-Parameters for Ridge Classifier***\r\n",
        "\r\n",
        "Ridge regression is a penalized linear regression model for predicting a numerical value.\r\n",
        "Nevertheless, it can be very effective when applied to classification.\r\n",
        "Perhaps the most important parameter to tune is the regularization strength (alpha). A good starting point might be values in the range [0.1 to 1.0]\r\n",
        "* alpha in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\r\n",
        "\r\n",
        "###***Hyper-Parameters for K-Nearest Neighbors (KNN)***\r\n",
        "\r\n",
        "The most important hyperparameter for KNN is the number of neighbors (n_neighbors).\r\n",
        "\r\n",
        "Test values between at least 1 and 21, perhaps just the odd numbers.\r\n",
        "\r\n",
        "* n_neighbors in [1 to 21]\r\n",
        "It may also be interesting to test different distance metrics (metric) for choosing the composition of the neighborhood.\r\n",
        "\r\n",
        "* metric in [‘euclidean’, ‘manhattan’, ‘minkowski’]\r\n",
        "\r\n",
        "* weights in [‘uniform’, ‘distance’]\r\n",
        "\r\n",
        "###***Hyper-Parameters for Support Vector Machine (SVM)***\r\n",
        "\r\n",
        "The SVM algorithm, like gradient boosting, is very popular, very effective, and provides a large number of hyperparameters to tune.\r\n",
        "Perhaps the first important parameter is the choice of kernel that will control the manner in which the input variables will be projected. There are many to choose from, but linear, polynomial, and RBF are the most common, perhaps just linear and RBF in practice.\r\n",
        "\r\n",
        "* kernels in [‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’]\r\n",
        "If the polynomial kernel works out, then it is a good idea to dive into the degree hyperparameter.\r\n",
        "\r\n",
        "Another critical parameter is the penalty (C) that can take on a range of values and has a dramatic effect on the shape of the resulting regions for each class. A log scale might be a good starting point.\r\n",
        "\r\n",
        "* C in [100, 10, 1.0, 0.1, 0.001]\r\n",
        "\r\n",
        "###***Hyper-Parameters for Bagged Decision Trees (Bagging)***\r\n",
        "The most important parameter for bagged decision trees is the number of trees (n_estimators).\r\n",
        "\r\n",
        "Ideally, this should be increased until no further improvement is seen in the model.\r\n",
        "\r\n",
        "Good values might be a log scale from 10 to 1,000.\r\n",
        "\r\n",
        "* n_estimators in [10, 100, 1000]\r\n",
        "\r\n",
        "###***Hyper-Parameters for Random Forest***\r\n",
        "The most important parameter is the number of random features to sample at each split point (max_features).\r\n",
        "\r\n",
        "You could try a range of integer values, such as 1 to 20, or 1 to half the number of input features.\r\n",
        "\r\n",
        "* max_features [1 to 20]\r\n",
        "Alternately, you could try a suite of different default value calculators.\r\n",
        "\r\n",
        "* max_features in [‘sqrt’, ‘log2’]\r\n",
        "Another important parameter for random forest is the number of trees * * ******(n_estimators).\r\n",
        "\r\n",
        "Ideally, this should be increased until no further improvement is seen in the model.\r\n",
        "\r\n",
        "Good values might be a log scale from 10 to 1,000.\r\n",
        "\r\n",
        "* n_estimators in [10, 100, 1000]\r\n",
        "\r\n",
        "###***Hyper-Parameters for Stochastic Gradient Boosting\r\n",
        "Also called Gradient Boosting Machine (GBM) or named for the specific implementation, such as XGBoost.\r\n",
        "The gradient boosting algorithm has many parameters to tune.\r\n",
        "\r\n",
        "There are some parameter pairings that are important to consider. The first is the learning rate, also called shrinkage or eta (learning_rate) and the number of trees in the model (n_estimators). Both could be considered on a log scale, although in different directions.\r\n",
        "\r\n",
        "* learning_rate in [0.001, 0.01, 0.1]\r\n",
        "* n_estimators [10, 100, 1000]\r\n",
        "Another pairing is the number of rows or subset of the data to consider for each tree (subsample) and the depth of each tree (max_depth). These could be grid searched at a 0.1 and 1 interval respectively, although common values can be tested directly.\r\n",
        "\r\n",
        "* subsample in [0.5, 0.7, 1.0]\r\n",
        "* max_depth in [3, 7, 9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfRw8FwvwGfB"
      },
      "source": [
        "##**1-Logistic Regression**\r\n",
        "\r\n",
        "Logistic regression does not really have any critical hyperparameters to tune.\r\n",
        "\r\n",
        "Sometimes, you can see useful differences in performance or convergence with different solvers (solver).\r\n",
        "\r\n",
        "* solver in [‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’]\r\n",
        "Regularization (penalty) can sometimes be helpful.\r\n",
        "\r\n",
        "* penalty in [‘none’, ‘l1’, ‘l2’, ‘elasticnet’]\r\n",
        "Note: not all solvers support all regularization terms.\r\n",
        "\r\n",
        "* The C parameter controls the penality strength, which can also be effective.\r\n",
        "C in [100, 10, 1.0, 0.1, 0.01]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poDbTk8PvoCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abb01d44-5910-49ed-914b-253d03fe6e36"
      },
      "source": [
        "# example of grid searching key hyperparametres for logistic regression\r\n",
        "from sklearn.datasets import make_blobs\r\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "# define dataset\r\n",
        "X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\r\n",
        "# define models and parameters\r\n",
        "model = LogisticRegression()\r\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear']\r\n",
        "penalty = ['l2']\r\n",
        "c_values = [100, 10, 1.0, 0.1, 0.01]\r\n",
        "# define grid search\r\n",
        "grid = dict(solver=solvers,penalty=penalty,C=c_values)\r\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\r\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\r\n",
        "grid_result = grid_search.fit(X, y)\r\n",
        "# summarize results\r\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
        "means = grid_result.cv_results_['mean_test_score']\r\n",
        "stds = grid_result.cv_results_['std_test_score']\r\n",
        "params = grid_result.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.952000 using {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.942000 (0.019391) with: {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.940333 (0.024424) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.942000 (0.021354) with: {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.944333 (0.020279) with: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.943000 (0.023259) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.942667 (0.021746) with: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.945333 (0.020287) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.942333 (0.021242) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.943000 (0.021315) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.946000 (0.020100) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.946333 (0.019576) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.946667 (0.019206) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "0.950333 (0.021211) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.950333 (0.021211) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.952000 (0.016813) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2o4HUSmxHFb"
      },
      "source": [
        "##**2-Ridge Classifier**\r\n",
        "\r\n",
        "Ridge regression is a penalized linear regression model for predicting a numerical value.\r\n",
        "\r\n",
        "Nevertheless, it can be very effective when applied to classification.\r\n",
        "\r\n",
        "Perhaps the most important parameter to tune is the regularization strength (alpha). A good starting point might be values in the range [0.1 to 1.0]\r\n",
        "\r\n",
        "* alpha in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd1gFmRUxwGP",
        "outputId": "2ee9a3dc-2001-444b-a1b0-111c95228cb0"
      },
      "source": [
        "# example of grid searching key hyperparametres for ridge classifier\r\n",
        "from sklearn.datasets import make_blobs\r\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.linear_model import RidgeClassifier\r\n",
        "# define dataset\r\n",
        "X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\r\n",
        "# define models and parameters\r\n",
        "model = RidgeClassifier()\r\n",
        "alpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\r\n",
        "# define grid search\r\n",
        "grid = dict(alpha=alpha)\r\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\r\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\r\n",
        "grid_result = grid_search.fit(X, y)\r\n",
        "# summarize results\r\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
        "means = grid_result.cv_results_['mean_test_score']\r\n",
        "stds = grid_result.cv_results_['std_test_score']\r\n",
        "params = grid_result.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.963667 using {'alpha': 0.1}\n",
            "0.963667 (0.016630) with: {'alpha': 0.1}\n",
            "0.963667 (0.016630) with: {'alpha': 0.2}\n",
            "0.963667 (0.016630) with: {'alpha': 0.3}\n",
            "0.963667 (0.016630) with: {'alpha': 0.4}\n",
            "0.963667 (0.016630) with: {'alpha': 0.5}\n",
            "0.963667 (0.016630) with: {'alpha': 0.6}\n",
            "0.963667 (0.016630) with: {'alpha': 0.7}\n",
            "0.963667 (0.016630) with: {'alpha': 0.8}\n",
            "0.963667 (0.016630) with: {'alpha': 0.9}\n",
            "0.963667 (0.016630) with: {'alpha': 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEUwGliox9FR"
      },
      "source": [
        "##**3-K-Nearest Neighbors (KNN)**\r\n",
        "\r\n",
        "The most important hyperparameter for KNN is the number of neighbors (n_neighbors).\r\n",
        "\r\n",
        "Test values between at least 1 and 21, perhaps just the odd numbers.\r\n",
        "\r\n",
        "* n_neighbors in [1 to 21]\r\n",
        "It may also be interesting to test different distance metrics (metric) for choosing the composition of the neighborhood.\r\n",
        "\r\n",
        "* metric in [‘euclidean’, ‘manhattan’, ‘minkowski’]\r\n",
        "It may also be interesting to test the contribution of members of the neighborhood via different weightings (weights).\r\n",
        "\r\n",
        "* weights in [‘uniform’, ‘distance’]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0wvhgfuyXyb",
        "outputId": "59128dcd-3820-45b8-f5fe-dfa5bec50564"
      },
      "source": [
        "# example of grid searching key hyperparametres for KNeighborsClassifier\r\n",
        "from sklearn.datasets import make_blobs\r\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "# define dataset\r\n",
        "X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\r\n",
        "# define models and parameters\r\n",
        "model = KNeighborsClassifier()\r\n",
        "n_neighbors = range(1, 21, 2)\r\n",
        "weights = ['uniform', 'distance']\r\n",
        "metric = ['euclidean', 'manhattan', 'minkowski']\r\n",
        "# define grid search\r\n",
        "grid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)\r\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\r\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\r\n",
        "grid_result = grid_search.fit(X, y)\r\n",
        "# summarize results\r\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
        "means = grid_result.cv_results_['mean_test_score']\r\n",
        "stds = grid_result.cv_results_['std_test_score']\r\n",
        "params = grid_result.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.972333 using {'metric': 'euclidean', 'n_neighbors': 19, 'weights': 'uniform'}\n",
            "0.864000 (0.031581) with: {'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'uniform'}\n",
            "0.864000 (0.031581) with: {'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'distance'}\n",
            "0.927667 (0.024857) with: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}\n",
            "0.927667 (0.024857) with: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "0.945333 (0.019788) with: {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'uniform'}\n",
            "0.945333 (0.019788) with: {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}\n",
            "0.954000 (0.017626) with: {'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'uniform'}\n",
            "0.954000 (0.017626) with: {'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'distance'}\n",
            "0.964000 (0.013808) with: {'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'uniform'}\n",
            "0.964000 (0.013808) with: {'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'distance'}\n",
            "0.963333 (0.014453) with: {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'uniform'}\n",
            "0.963333 (0.014453) with: {'metric': 'euclidean', 'n_neighbors': 11, 'weights': 'distance'}\n",
            "0.963667 (0.016017) with: {'metric': 'euclidean', 'n_neighbors': 13, 'weights': 'uniform'}\n",
            "0.963667 (0.016017) with: {'metric': 'euclidean', 'n_neighbors': 13, 'weights': 'distance'}\n",
            "0.969667 (0.013780) with: {'metric': 'euclidean', 'n_neighbors': 15, 'weights': 'uniform'}\n",
            "0.969667 (0.013780) with: {'metric': 'euclidean', 'n_neighbors': 15, 'weights': 'distance'}\n",
            "0.970000 (0.015706) with: {'metric': 'euclidean', 'n_neighbors': 17, 'weights': 'uniform'}\n",
            "0.970000 (0.015706) with: {'metric': 'euclidean', 'n_neighbors': 17, 'weights': 'distance'}\n",
            "0.972333 (0.013828) with: {'metric': 'euclidean', 'n_neighbors': 19, 'weights': 'uniform'}\n",
            "0.972333 (0.013828) with: {'metric': 'euclidean', 'n_neighbors': 19, 'weights': 'distance'}\n",
            "0.856667 (0.028206) with: {'metric': 'manhattan', 'n_neighbors': 1, 'weights': 'uniform'}\n",
            "0.856667 (0.028206) with: {'metric': 'manhattan', 'n_neighbors': 1, 'weights': 'distance'}\n",
            "0.912333 (0.025649) with: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'uniform'}\n",
            "0.912333 (0.025649) with: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "0.936667 (0.021029) with: {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'uniform'}\n",
            "0.936667 (0.021029) with: {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}\n",
            "0.944000 (0.019425) with: {'metric': 'manhattan', 'n_neighbors': 7, 'weights': 'uniform'}\n",
            "0.944000 (0.019425) with: {'metric': 'manhattan', 'n_neighbors': 7, 'weights': 'distance'}\n",
            "0.953333 (0.018679) with: {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'uniform'}\n",
            "0.953333 (0.018679) with: {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'distance'}\n",
            "0.959333 (0.017876) with: {'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'uniform'}\n",
            "0.959333 (0.017876) with: {'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'distance'}\n",
            "0.959667 (0.016829) with: {'metric': 'manhattan', 'n_neighbors': 13, 'weights': 'uniform'}\n",
            "0.959667 (0.016829) with: {'metric': 'manhattan', 'n_neighbors': 13, 'weights': 'distance'}\n",
            "0.962333 (0.012565) with: {'metric': 'manhattan', 'n_neighbors': 15, 'weights': 'uniform'}\n",
            "0.962333 (0.012565) with: {'metric': 'manhattan', 'n_neighbors': 15, 'weights': 'distance'}\n",
            "0.966000 (0.014048) with: {'metric': 'manhattan', 'n_neighbors': 17, 'weights': 'uniform'}\n",
            "0.966000 (0.014048) with: {'metric': 'manhattan', 'n_neighbors': 17, 'weights': 'distance'}\n",
            "0.967667 (0.013337) with: {'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'uniform'}\n",
            "0.967667 (0.013337) with: {'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'distance'}\n",
            "0.864000 (0.031581) with: {'metric': 'minkowski', 'n_neighbors': 1, 'weights': 'uniform'}\n",
            "0.864000 (0.031581) with: {'metric': 'minkowski', 'n_neighbors': 1, 'weights': 'distance'}\n",
            "0.927667 (0.024857) with: {'metric': 'minkowski', 'n_neighbors': 3, 'weights': 'uniform'}\n",
            "0.927667 (0.024857) with: {'metric': 'minkowski', 'n_neighbors': 3, 'weights': 'distance'}\n",
            "0.945333 (0.019788) with: {'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'uniform'}\n",
            "0.945333 (0.019788) with: {'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'distance'}\n",
            "0.954000 (0.017626) with: {'metric': 'minkowski', 'n_neighbors': 7, 'weights': 'uniform'}\n",
            "0.954000 (0.017626) with: {'metric': 'minkowski', 'n_neighbors': 7, 'weights': 'distance'}\n",
            "0.964000 (0.013808) with: {'metric': 'minkowski', 'n_neighbors': 9, 'weights': 'uniform'}\n",
            "0.964000 (0.013808) with: {'metric': 'minkowski', 'n_neighbors': 9, 'weights': 'distance'}\n",
            "0.963333 (0.014453) with: {'metric': 'minkowski', 'n_neighbors': 11, 'weights': 'uniform'}\n",
            "0.963333 (0.014453) with: {'metric': 'minkowski', 'n_neighbors': 11, 'weights': 'distance'}\n",
            "0.963667 (0.016017) with: {'metric': 'minkowski', 'n_neighbors': 13, 'weights': 'uniform'}\n",
            "0.963667 (0.016017) with: {'metric': 'minkowski', 'n_neighbors': 13, 'weights': 'distance'}\n",
            "0.969667 (0.013780) with: {'metric': 'minkowski', 'n_neighbors': 15, 'weights': 'uniform'}\n",
            "0.969667 (0.013780) with: {'metric': 'minkowski', 'n_neighbors': 15, 'weights': 'distance'}\n",
            "0.970000 (0.015706) with: {'metric': 'minkowski', 'n_neighbors': 17, 'weights': 'uniform'}\n",
            "0.970000 (0.015706) with: {'metric': 'minkowski', 'n_neighbors': 17, 'weights': 'distance'}\n",
            "0.972333 (0.013828) with: {'metric': 'minkowski', 'n_neighbors': 19, 'weights': 'uniform'}\n",
            "0.972333 (0.013828) with: {'metric': 'minkowski', 'n_neighbors': 19, 'weights': 'distance'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpNr_9M5yqMf"
      },
      "source": [
        "##**4-Support Vector Machine (SVM)**\r\n",
        "The SVM algorithm, like gradient boosting, is very popular, very effective, and provides a large number of hyperparameters to tune.\r\n",
        "\r\n",
        "Perhaps the first important parameter is the choice of kernel that will control the manner in which the input variables will be projected. There are many to choose from, but linear, polynomial, and RBF are the most common, perhaps just linear and RBF in practice.\r\n",
        "\r\n",
        "* kernels in [‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’]\r\n",
        "If the polynomial kernel works out, then it is a good idea to dive into the degree hyperparameter.\r\n",
        "\r\n",
        "Another critical parameter is the penalty (C) that can take on a range of values and has a dramatic effect on the shape of the resulting regions for each class. A log scale might be a good starting point.\r\n",
        "\r\n",
        "* C in [100, 10, 1.0, 0.1, 0.001]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97CfKcBDy_JE",
        "outputId": "795101a1-98f2-4b93-bcb5-7f4479d84a35"
      },
      "source": [
        "# example of grid searching key hyperparametres for SVC\r\n",
        "from sklearn.datasets import make_blobs\r\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.svm import SVC\r\n",
        "# define dataset\r\n",
        "X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\r\n",
        "# define model and parameters\r\n",
        "model = SVC()\r\n",
        "kernel = ['poly', 'rbf', 'sigmoid']\r\n",
        "C = [50, 10, 1.0, 0.1, 0.01]\r\n",
        "gamma = ['scale']\r\n",
        "# define grid search\r\n",
        "grid = dict(kernel=kernel,C=C,gamma=gamma)\r\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\r\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\r\n",
        "grid_result = grid_search.fit(X, y)\r\n",
        "# summarize results\r\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
        "means = grid_result.cv_results_['mean_test_score']\r\n",
        "stds = grid_result.cv_results_['std_test_score']\r\n",
        "params = grid_result.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.972000 using {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "0.970667 (0.014817) with: {'C': 50, 'gamma': 'scale', 'kernel': 'poly'}\n",
            "0.968667 (0.016275) with: {'C': 50, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "0.947000 (0.026096) with: {'C': 50, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
            "0.970667 (0.014817) with: {'C': 10, 'gamma': 'scale', 'kernel': 'poly'}\n",
            "0.968667 (0.016275) with: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "0.955333 (0.021561) with: {'C': 10, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
            "0.969000 (0.014224) with: {'C': 1.0, 'gamma': 'scale', 'kernel': 'poly'}\n",
            "0.967667 (0.015206) with: {'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "0.961333 (0.019102) with: {'C': 1.0, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
            "0.927333 (0.025811) with: {'C': 0.1, 'gamma': 'scale', 'kernel': 'poly'}\n",
            "0.972000 (0.012490) with: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "0.968667 (0.014772) with: {'C': 0.1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
            "0.927333 (0.025811) with: {'C': 0.01, 'gamma': 'scale', 'kernel': 'poly'}\n",
            "0.961333 (0.016275) with: {'C': 0.01, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "0.970000 (0.013663) with: {'C': 0.01, 'gamma': 'scale', 'kernel': 'sigmoid'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7LFCt5-zXIw"
      },
      "source": [
        "##**5-Bagged Decision Trees (Bagging)**\r\n",
        "The most important parameter for bagged decision trees is the number of trees (n_estimators).\r\n",
        "Ideally, this should be increased until no further improvement is seen in the model.\r\n",
        "Good values might be a log scale from 10 to 1,000.\r\n",
        "\r\n",
        "* n_estimators in [10, 100, 1000]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "zxEUMpZHzrGY",
        "outputId": "6cf3d761-4c08-4a23-bafd-a69be5b7480d"
      },
      "source": [
        "# example of grid searching key hyperparameters for BaggingClassifier\r\n",
        "from sklearn.datasets import make_blobs\r\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.ensemble import BaggingClassifier\r\n",
        "# define dataset\r\n",
        "X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\r\n",
        "# define models and parameters\r\n",
        "model = BaggingClassifier()\r\n",
        "n_estimators = [10, 100, 1000]\r\n",
        "# define grid search\r\n",
        "grid = dict(n_estimators=n_estimators)\r\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\r\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\r\n",
        "grid_result = grid_search.fit(X, y)\r\n",
        "# summarize results\r\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
        "means = grid_result.cv_results_['mean_test_score']\r\n",
        "stds = grid_result.cv_results_['std_test_score']\r\n",
        "params = grid_result.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-31d1c130748f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRepeatedStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whrk2w0cz_EA"
      },
      "source": [
        "##**6-Random Forest**\r\n",
        "\r\n",
        "The most important parameter is the number of random features to sample at each split point (max_features).\r\n",
        "You could try a range of integer values, such as 1 to 20, or 1 to half the number of input features.\r\n",
        "* max_features [1 to 20]\r\n",
        "Alternately, you could try a suite of different default value calculators.\r\n",
        "\r\n",
        "* max_features in [‘sqrt’, ‘log2’]\r\n",
        "Another important parameter for random forest is the number of trees (n_estimators).\r\n",
        "\r\n",
        "Ideally, this should be increased until no further improvement is seen in the model.\r\n",
        "\r\n",
        "Good values might be a log scale from 10 to 1,000.\r\n",
        "\r\n",
        "* n_estimators in [10, 100, 1000]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "dL7COqH50VWF",
        "outputId": "d06c77cb-acdc-43d1-9716-4da5f5ec7f79"
      },
      "source": [
        "# example of grid searching key hyperparameters for RandomForestClassifier\r\n",
        "from sklearn.datasets import make_blobs\r\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "# define dataset\r\n",
        "X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\r\n",
        "# define models and parameters\r\n",
        "model = RandomForestClassifier()\r\n",
        "n_estimators = [10, 100, 1000]\r\n",
        "max_features = ['sqrt', 'log2']\r\n",
        "# define grid search\r\n",
        "grid = dict(n_estimators=n_estimators,max_features=max_features)\r\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\r\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\r\n",
        "grid_result = grid_search.fit(X, y)\r\n",
        "# summarize results\r\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
        "means = grid_result.cv_results_['mean_test_score']\r\n",
        "stds = grid_result.cv_results_['std_test_score']\r\n",
        "params = grid_result.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-569930bb06cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRepeatedStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4be0doa0mR0"
      },
      "source": [
        "##**7-Stochastic Gradient Boosting**\r\n",
        "\r\n",
        "Also called Gradient Boosting Machine (GBM) or named for the specific implementation, such as XGBoost.\r\n",
        "\r\n",
        "The gradient boosting algorithm has many parameters to tune.\r\n",
        "\r\n",
        "There are some parameter pairings that are important to consider. The first is the learning rate, also called shrinkage or eta (learning_rate) and the number of trees in the model (n_estimators). Both could be considered on a log scale, although in different directions.\r\n",
        "\r\n",
        "* learning_rate in [0.001, 0.01, 0.1]\r\n",
        "* n_estimators [10, 100, 1000]\r\n",
        "Another pairing is the number of rows or subset of the data to consider for each tree (subsample) and the depth of each tree (max_depth). These could be grid searched at a 0.1 and 1 interval respectively, although common values can be tested directly.\r\n",
        "\r\n",
        "* subsample in [0.5, 0.7, 1.0]\r\n",
        "* max_depth in [3, 7, 9]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "iB9LlOqi1AJY",
        "outputId": "8a8ae810-f477-462e-e533-40b8ff9d7afe"
      },
      "source": [
        "# example of grid searching key hyperparameters for GradientBoostingClassifier\r\n",
        "from sklearn.datasets import make_blobs\r\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.ensemble import GradientBoostingClassifier\r\n",
        "# define dataset\r\n",
        "X, y = make_blobs(n_samples=1000, centers=2, n_features=100, cluster_std=20)\r\n",
        "# define models and parameters\r\n",
        "model = GradientBoostingClassifier()\r\n",
        "n_estimators = [10, 100, 1000]\r\n",
        "learning_rate = [0.001, 0.01, 0.1]\r\n",
        "subsample = [0.5, 0.7, 1.0]\r\n",
        "max_depth = [3, 7, 9]\r\n",
        "# define grid search\r\n",
        "grid = dict(learning_rate=learning_rate, n_estimators=n_estimators, subsample=subsample, max_depth=max_depth)\r\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\r\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\r\n",
        "grid_result = grid_search.fit(X, y)\r\n",
        "# summarize results\r\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\r\n",
        "means = grid_result.cv_results_['mean_test_score']\r\n",
        "stds = grid_result.cv_results_['std_test_score']\r\n",
        "params = grid_result.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-be987e2e9691>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRepeatedStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOIBSb9z23OD"
      },
      "source": [
        "##**8-K-Means**\r\n",
        "\r\n",
        "Tune the k-means model with the following hyperparameters. The hyperparameters that have the greatest impact on k-means objective metrics are: mini_batch_size, extra_center_factor, and init_method. Tuning the hyperparameter epochs generally results in minor improvements.\r\n",
        "\r\n",
        "Parameter Name\tParameter Type\tRecommended Ranges\r\n",
        "* epochs\t- MinValue: 1, MaxValue:10\r\n",
        "* extra_center_factor\t- MinValue: 4, MaxValue:10\r\n",
        "* init_method\t- ['kmeans++', 'random']\r\n",
        "* mini_batch_size\t- MinValue: 3000, MaxValue:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYd0MuR24YAT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}