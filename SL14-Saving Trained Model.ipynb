{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SL14-Saving Trained Model",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnihiEiBUqQR"
      },
      "source": [
        "#**Save and Load Machine Learning Models**\r\n",
        "\r\n",
        "Finding an accurate machine learning model is not the end of the project.\r\n",
        "\r\n",
        "In this post you will discover how to save and load your machine learning model in Python using scikit-learn.\r\n",
        "\r\n",
        "This allows you to save your model to file and load it later in order to make predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDbs_eGtVbkx"
      },
      "source": [
        "##**1-Pickle**\r\n",
        "\r\n",
        "Pickle is the standard way of serializing objects in Python.\r\n",
        "\r\n",
        "You can use the pickle operation to serialize your machine learning algorithms and save the serialized format to a file.\r\n",
        "\r\n",
        "Later you can load this file to deserialize your model and use it to make new predictions.\r\n",
        "\r\n",
        "The example below demonstrates how you can train a logistic regression model on the Pima Indians onset of diabetes dataset, save the model to file and load it to make predictions on the unseen test set \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoVZzHpgV7pt",
        "outputId": "2c88d5af-95e4-4662-bb6b-34cdc0f1f009"
      },
      "source": [
        "# PICKLE\r\n",
        "\r\n",
        "import numpy as np \r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "# Load dataset \r\n",
        "from sklearn.datasets import load_iris \r\n",
        "iris = load_iris() \r\n",
        "\r\n",
        "X = iris.data \r\n",
        "y = iris.target \r\n",
        "\r\n",
        "# Split dataset into train and test \r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3) \r\n",
        "\r\n",
        "# import KNeighborsClassifier model \r\n",
        "from sklearn.neighbors import KNeighborsClassifier as KNN \r\n",
        "knn = KNN(n_neighbors = 3) \r\n",
        "\r\n",
        "# train model \r\n",
        "knn.fit(X_train, y_train) \r\n",
        "\r\n",
        "import pickle \r\n",
        "\r\n",
        "# Save the trained model as a pickle string. \r\n",
        "saved_model = pickle.dumps(knn) \r\n",
        "\r\n",
        "# Load the pickled model \r\n",
        "knn_from_pickle = pickle.loads(saved_model) \r\n",
        "\r\n",
        "# Use the loaded pickled model to make predictions \r\n",
        "knn_from_pickle.predict(X_test) \r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 2, 0, 0, 1, 0, 1, 0, 1, 2, 2, 1, 2, 0, 2, 0, 0, 2, 0, 0,\n",
              "       1, 2, 1, 2, 1, 2, 0, 0, 0, 0, 1, 0, 1, 0, 1, 2, 1, 0, 2, 2, 1, 0,\n",
              "       2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGh5IFWOYZA3"
      },
      "source": [
        "##**2-Joblib**\r\n",
        "\r\n",
        "Joblib is part of the SciPy ecosystem and provides utilities for pipelining Python jobs.\r\n",
        "\r\n",
        "It provides utilities for saving and loading Python objects that make use of NumPy data structures, efficiently.\r\n",
        "\r\n",
        "This can be useful for some machine learning algorithms that require a lot of parameters or store the entire dataset (like K-Nearest Neighbors).\r\n",
        "\r\n",
        "The example below demonstrates how you can train a logistic regression model on the Pima Indians onset of diabetes dataset, saves the model to file using joblib and load it to make predictions on the unseen test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJL13kJGZC6L",
        "outputId": "fcedb410-0733-41ad-d521-4b21510bcd18"
      },
      "source": [
        "# JOBLIB\r\n",
        "\r\n",
        "import numpy as np \r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import joblib\r\n",
        "# Load dataset \r\n",
        "from sklearn.datasets import load_iris \r\n",
        "iris = load_iris() \r\n",
        "\r\n",
        "X = iris.data \r\n",
        "y = iris.target \r\n",
        "\r\n",
        "# Split dataset into train and test \r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3) \r\n",
        "\r\n",
        "# import KNeighborsClassifier model \r\n",
        "from sklearn.neighbors import KNeighborsClassifier as KNN \r\n",
        "model = KNN(n_neighbors = 3) \r\n",
        "\r\n",
        "# train model \r\n",
        "model.fit(X_train, y_train) \r\n",
        "\r\n",
        "# save the model to disk\r\n",
        "filename = 'finalized_model.sav'\r\n",
        "joblib.dump(model, filename)\r\n",
        " \r\n",
        "# some time later...\r\n",
        " \r\n",
        "# load the model from disk\r\n",
        "loaded_model = joblib.load(filename)\r\n",
        "result = loaded_model.score(X_test, y_test)\r\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}